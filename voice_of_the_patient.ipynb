{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e388ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1: Setup audio recorder(ffmpeg , pyaudio & portaudio) \n",
    "#ffmped allows video, audio and image processing\n",
    "import logging\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98373bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 01:11:13,429 - INFO - Adjusting for ambient noise...\n",
      "2025-04-20 01:11:14,431 - INFO - Start speaking now...\n",
      "2025-04-20 01:11:19,520 - INFO - Recording complete.\n",
      "2025-04-20 01:11:19,673 - INFO - Audio saved to patient_voice_test_for_patient.mp3\n"
     ]
    }
   ],
   "source": [
    "#step 1b \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "#level is parameter :info is min, format m time -> level kya info ,debug -> message \n",
    "def record_audio(file_path, timeout=20, phrase_time_limit=None):\n",
    "    \"\"\"\n",
    "    Simplified function to record audio from the microphone and save it as an MP3 file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to save the recorded audio file.\n",
    "    timeout (int): Maximum time to wait for a phrase to start (in seconds).\n",
    "    phrase_time_lfimit (int): Maximum time for the phrase to be recorded (in seconds).\n",
    "    \"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    #initializing used to store the audio collected from microphone\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            logging.info(\"Adjusting for ambient noise...\")\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=1)#background k noise ko ignore\n",
    "            logging.info(\"Start speaking now...\")\n",
    "            \n",
    "            # Record the audio\n",
    "            audio_data = recognizer.listen(source, timeout=timeout, phrase_time_limit=phrase_time_limit)#timeout time tk wait if no noise then bnd ho jayega and pharse time tk audio record krega\n",
    "            logging.info(\"Recording complete.\")\n",
    "            \n",
    "            # Convert the recorded audio to an MP3 file\n",
    "            wav_data = audio_data.get_wav_data()#convert the recorded audio in wave format\n",
    "            audio_segment = AudioSegment.from_wav(BytesIO(wav_data))#conver wave into file type so that pydub can read\n",
    "            audio_segment.export(file_path, format=\"mp3\", bitrate=\"128k\")#save the file in mp3 format\n",
    "            \n",
    "            logging.info(f\"Audio saved to {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "audio_filepath=\"patient_voice_test_for_patient.mp3\"\n",
    "#record_audio(file_path=audio_filepath)\n",
    "record_audio(audio_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32bebab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 :convert audio into text(so that audio can be used as text in brain)\n",
    "import os\n",
    "from groq import Groq\n",
    "GROQ_API_KEY=os.environ.get(\"GROQ_API_KEY\")\n",
    "client=Groq(api_key=GROQ_API_KEY)\n",
    "stt_model=\"whisper-large-v3-turbo\"#speech to text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3558877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 01:11:58,025 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/audio/transcriptions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This channel is here. Hi, mic testing, mic testing, mic testing.\n"
     ]
    }
   ],
   "source": [
    "audio_file=open(audio_filepath, \"rb\")#open as rb read binary\n",
    "transcription=client.audio.transcriptions.create(\n",
    "    model=stt_model,\n",
    "    file=audio_file,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
